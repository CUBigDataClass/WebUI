<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">
<html xmlns="http://www.w3.org/1999/xhtml">
<head>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
<title>TopXX</title>

<!-- Bootstrap -->
<link href="css/bootstrap.min.css" rel="stylesheet" media="screen">
<link rel="shortcut icon" href="favicon.ico" />
<script src="http://code.jquery.com/jquery.js"></script>
<script src="js/bootstrap.min.js"></script>
</head>
<body>
<nav class="navbar navbar-default navbar-fixed-top" role="navigation">
  <div class="container-fluid">
    <!-- Brand and toggle get grouped for better mobile display -->
    <div class="navbar-header">
      <button type="button" class="navbar-toggle" data-toggle="collapse" data-target="#bs-example-navbar-collapse-1">
        <span class="sr-only">Toggle navigation</span>
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
      </button>
      <a class="navbar-brand" href="#">Twitter EmotiMap</a>
    </div>

    <!-- Collect the nav links, forms, and other content for toggling -->
    <div class="collapse navbar-collapse" id="bs-example-navbar-collapse-1">
      <ul class="nav navbar-nav">
        <li class="active"><a href="#">Home</a></li>
        <li><a href="about.html">About</a></li>
        <li><a href="stats.html">Map</a></li>
        <li class="dropdown">
          <a href="#" class="dropdown-toggle" data-toggle="dropdown">More <b class="caret"></b></a>
          <ul class="dropdown-menu">
            <li><a href="proposal.html">Project Text</a></li>
            <li class="divider"></li>
            <li><a href="matt.html">Matt Gross</a></li>
            <li><a href="max.html">Max Trotter</a></li>
            <li><a href="brian.html">Brian McWilliams</a></li>
            <li><a href="andrew.html">Andrew Mahan</a></li>
            <li><a href="dillon.html">Dillon Fancher</a></li>
          </ul>
        </li>
      </ul>
      <!--<form class="navbar-form navbar-left" role="search">
        <div class="form-group">
          <input type="text" class="form-control" placeholder="Search">
        </div>
        <button type="submit" class="btn btn-default">Submit</button>
      </form>
      <ul class="nav navbar-nav navbar-right">
        <li><a href="#">Link</a></li>
        <li class="dropdown">
          <a href="#" class="dropdown-toggle" data-toggle="dropdown">Dropdown <b class="caret"></b></a>
          <ul class="dropdown-menu">
            <li><a href="#">Action</a></li>
            <li><a href="#">Another action</a></li>
            <li><a href="#">Something else here</a></li>
            <li class="divider"></li>
            <li><a href="#">Separated link</a></li>
          </ul>
        </li>
      </ul>-->
    </div><!-- /.navbar-collapse -->
  </div><!-- /.container-fluid -->
</nav>

<div class="container-fluid" style="margin-top: 100px;">
  <div class="col-md-7">
    <div class="panel panel-default">
      <div class="panel-heading">
        <h5 class="panel-title">The Project</h5>
      </div>
      <div class="panel-body">
        TopXX (pronounced Topics) applies Big Data technology and concepts to 
        examine the Twitter Firehose and extract the top 20 words that have 
        been tweeted for major cities. These words are then displayed in a 
        visually dynamic manner to focus interest in the data.
        <br>
        <br>
        By creating a framework to gather, parse, and analyze tweets, we have 
        demonstrated a platform that can be used for deeper analysis of topics 
        and trends in targeted market segments.
        <br>
        <br>
        <br>
        <h5 class="panel-title">Data Workflow</h5>
        <br>
        A visual representation of the project workflow is presented under the
        ‘About' section.
        <br>
        <br>
        A server running in AWS EC2 uses the public Twitter API to gather 
        tweets from their firehose.  The API is used to filter the tweets to 
        those with geotagging enabled, in English, and from the Unites States.
        As the tweets come in, they are converted to strings and placed in a 
        Kafka queue.  
        <br>
        <br>
        This queue serves as a data source that Zookeeper vends out to a Kafka 
        consumer which first checks to see if the tweet is in one of our target
        cities.  If it is, the script cleans up the tweet text by removing 
        “filler” words such as “I”, “and”, and “or” which do not convey 
        information we need.  It also tokenizes, converts to lower case, and 
        removes @ and # data.   
        <br>
        <br>
        Once the data is parsed, its word count is inserted into a MongoDB 
        storage instance, with one JSON document for each city.  If the word 
        has not been seen before, it is added to the document.  If it exists, 
        the count is incremented.
        <br>
        <br>
        After the data is stored, a separate EC2 instance, serving as our web 
        server takes over.  When a user selects a city, a PHP request is sent 
        to the backend server’s MongoDB.  It returns an array of the top 20 
        tweeted words for that city, and the associated count.  The web server 
        front end can then present a color coded histogram of the data.
        <br>
        <br>
        <br>
        <h5 class="panel-title">Project History</h5>
        <br>
        As new information becomes available, a successful group needs to 
        adapt to the changing world around them.  As the semester progressed 
        and we were exposed to different areas of Big Data, our team examined, 
        explored, and shifted directions when appropriate.  
        <br>
        <br>
        Our project began as an attempt to examine tweets for emotional context
        and correlate that with a location.  By doing this we could compare how
        “happy” one location was to another.  We felt that this data could be 
        used for a wide range of people, from relators selling a particular 
        neighborhood to NGOs looking to focus their efforts.  
        <br>
        <br>
        To that end we created a script to begin gathering geotagged tweets on 
        developer systems.  This provided us with sample data, at a scale that 
        we could work with easily as we proceeded.  We also explored differnt 
        models for grouping and displaying these data points on a Google Map
        API.
        <br>
        <br>
        We examined using the Mechanical Turk to score lists of words on a 
        relative scale, say 1-10, but settled on a less precise, but easier to 
        obtain positive/negative classification.  
        <br>
        <br>
        A Hadoop instance was spun up but quickly abandoned as the batch nature
        of Hadoop did not fit with desire to present real time, changing 
        results.  Similarly Storm was investigated, but due to account 
        restrictions, only a single server deployment was completed.  It was 
        determined that while Storm would allow greater scalability, the amount
        of data we were dealing with did not warrant the complexity tradeoff.  
        <br>
        <br>
        We settled on Kafka queues and simply running against a larger EC2 
        instance as a solid foundation.  This removed much of the complexity in
        other technology stacks, and met our performance needs at a reasonable 
        cost.  The tradeoff of hardware VS developer time was very evident here.
        Kafka and Zookeeper also provided a path forward to span multiple 
        machines if growth warrants it, without needing to a complete rewrite of
        our backend processing structure.     
        <br>
        <br>
        Along the way, we explored LSA techniques for pullting other types of 
        information out of the tweet stream, eventually settling on some basic
        that served as proof of concept processing points.
        <br>
        <br>
        <br>
        <h5 class="panel-title">Future Applications</h5>
        <br>
        As stated previously, what we have dreaded is not so much a complete 
        product, but a flexible framework which can be tailored to future 
        situations.  Simple changes could include:
        <ul>
          <li>Narrowing the radius of locations to increase the precision of
              the data
          <li>Expand the number of locations processed
          <li>Customizing the list of words searched for - Instead of excluding 
              words we deem non-important, shifting to look for specific terms 
              such as “Coke” and “Pepsi” is trivial.
          <li>Scaling the infrastructure - moving the processing onto a series 
              of servers should be possible while still using the 
              Kafka/Zookeeper framework
          <li>Distributing the database -  A single instance of MongoDB is both 
              a bottleneck in performance and at risk as a single point of 
              failure
          <li>Improving insertion and search algorithms for the terms.
        </ul>
      </div>
    </div>
 </div>
</div>  

</body>
</html>
